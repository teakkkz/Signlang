{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "%matplotlib inline\n",
    "im =0\n",
    "im1 =0\n",
    "im2 =0\n",
    "im3 =0\n",
    "im4 =0\n",
    "im5 =0\n",
    "im6 =0\n",
    "im7 =0\n",
    "im8 =0\n",
    "im9 =0\n",
    "im10 =0\n",
    "im11 =0\n",
    "im12 =0\n",
    "im13 =0\n",
    "im14 =0\n",
    "im15 =0\n",
    "# # Load the image\n",
    "img_hot1 = []\n",
    "img_hot2 = []\n",
    "img_cold1 = []\n",
    "img_cool1 = []\n",
    "img_warm1 = []\n",
    "img_warm2 = []\n",
    "img_rain1 = []\n",
    "img_rain2 = []\n",
    "img_snow1 = []\n",
    "img_snow2 = []\n",
    "img_weather1 = []\n",
    "img_weather2 = []\n",
    "img_thunder1 = []\n",
    "img_thunder2 = []\n",
    "img_sun1 = []\n",
    "img_sun2 = []\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "### SUN HOT\n",
    "for root, directories, files in os.walk('/Users/tekz/Desktop/Sign Language/images/sun1/'):\n",
    "    for f in files:\n",
    "        img_sun1.append(cv2.imread('images/sun1/%d.jpg' % im))\n",
    "        im = im + 1\n",
    "        \n",
    "for root, directories, files in os.walk('/Users/tekz/Desktop/Sign Language/images/sun2/'):\n",
    "    for f in files:\n",
    "        img_sun2.append(cv2.imread('images/sun2/%d.jpg' % im1))\n",
    "        im1 = im1 + 1\n",
    "for root, directories, files in os.walk('/Users/tekz/Desktop/Sign Language/images/hot1/'):\n",
    "    for f in files:\n",
    "        img_hot1.append(cv2.imread('images/hot1/%d.jpg' % im2))\n",
    "        im2 = im2 + 1\n",
    "        \n",
    "for root, directories, files in os.walk('/Users/tekz/Desktop/Sign Language/images/hot2/'):\n",
    "    for f in files:\n",
    "        img_hot2.append(cv2.imread('images/hot2/%d.jpg'% im3))\n",
    "        im3 = im3 + 1\n",
    "              \n",
    "        \n",
    "###COOL COLD        \n",
    "for root, directories, files in os.walk('/Users/tekz/Desktop/Sign Language/images/cold1/'):\n",
    "    for f in files:\n",
    "        img_cold1.append(cv2.imread('images/cold1/%d.jpg' % im4))\n",
    "        im4 = im4 + 1\n",
    "\n",
    "for root, directories, files in os.walk('/Users/tekz/Desktop/Sign Language/images/cool1/'):\n",
    "    for f in files:\n",
    "        img_cool1.append(cv2.imread('images/cool1/%d.jpg' % im5))\n",
    "        im5 = im5 + 1\n",
    "\n",
    "###WARM WIND WEATHER\n",
    "\n",
    "for root, directories, files in os.walk('/Users/tekz/Desktop/Sign Language/images/warm1/'):\n",
    "    for f in files:\n",
    "        img_warm1.append(cv2.imread('images/warm1/%d.jpg' % im6))\n",
    "        im6 = im6 + 1\n",
    "for root, directories, files in os.walk('/Users/tekz/Desktop/Sign Language/images/warm2/'):\n",
    "    for f in files:\n",
    "        img_warm2.append(cv2.imread('images/warm2/%d.jpg' % im7))\n",
    "        im7 = im7 + 1\n",
    "for root, directories, files in os.walk('/Users/tekz/Desktop/Sign Language/images/weather1/'):\n",
    "    for f in files:\n",
    "        img_weather1.append(cv2.imread('images/weather1/%d.jpg' % im8))\n",
    "        im8 = im8 + 1\n",
    "for root, directories, files in os.walk('/Users/tekz/Desktop/Sign Language/images/weather2/'):\n",
    "    for f in files:\n",
    "        img_weather2.append(cv2.imread('images/weather2/%d.jpg' % im9))\n",
    "        im9 = im9 + 1\n",
    "\n",
    "###RAIN SNOW THUNDER        \n",
    "for root, directories, files in os.walk('/Users/tekz/Desktop/Sign Language/images/rain1/'):\n",
    "    for f in files:\n",
    "        img_rain1.append(cv2.imread('images/rain1/%d.jpg' % im10))\n",
    "        im10 = im10 + 1\n",
    "for root, directories, files in os.walk('/Users/tekz/Desktop/Sign Language/images/rain2/'):\n",
    "    for f in files:\n",
    "        img_rain2.append(cv2.imread('images/rain2/%d.jpg' % im11))\n",
    "        im11 = im + 1\n",
    "for root, directories, files in os.walk('/Users/tekz/Desktop/Sign Language/images/snow1/'):\n",
    "    for f in files:\n",
    "        img_snow1.append(cv2.imread('images/snow1/%d.jpg' % im12))\n",
    "        im12 = im + 1\n",
    "for root, directories, files in os.walk('/Users/tekz/Desktop/Sign Language/images/snow2/'):\n",
    "    for f in files:\n",
    "        img_snow2.append(cv2.imread('images/snow2/%d.jpg' % im13))\n",
    "        im13 = im13 + 1\n",
    "        \n",
    "for root, directories, files in os.walk('/Users/tekz/Desktop/Sign Language/images/thunder1/'):\n",
    "    for f in files:\n",
    "        img_thunder1.append(cv2.imread('images/thunder1/%d.jpg' % im14))\n",
    "        im14 = im14 + 1\n",
    "for root, directories, files in os.walk('/Users/tekz/Desktop/Sign Language/images/thunder2/'):\n",
    "    for f in files:\n",
    "        img_thunder2.append(cv2.imread('images/thunder2/%d.jpg' % im15))\n",
    "        im15 = im + 1\n",
    "\n",
    "#แปลงรูปเป็น GRAY ด้วย ก่อนหา keypoint\n",
    "        \n",
    "        \n",
    "\n",
    "# # Convert the training image to RGB\n",
    "# training_image = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)\n",
    "# # Convert the training image to gray scale\n",
    "# training_gray = cv2.cvtColor(training_image, cv2.COLOR_RGB2GRAY)\n",
    "# # Create test image by adding Scale Invariance and Rotational Invariance\n",
    "# test_image = cv2.pyrDown(training_image)\n",
    "# test_image = cv2.pyrDown(test_image)\n",
    "# num_rows, num_cols = test_image.shape[:2]\n",
    "# rotation_matrix = cv2.getRotationMatrix2D((num_cols/2, num_rows/2), 30, 1)\n",
    "# test_image = cv2.warpAffine(test_image, rotation_matrix, (num_cols, num_rows))\n",
    "# test_gray = cv2.cvtColor(test_image, cv2.COLOR_RGB2GRAY)\n",
    "# # Display traning image and testing image\n",
    "# fx, plots = plt.subplots(1, 2, figsize=(20,10))\n",
    "# plots[0].set_title(\"Training Image\")\n",
    "# plots[0].imshow(training_image)\n",
    "# plots[1].set_title(\"Testing Image\")\n",
    "# plots[1].imshow(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ไอนี่ไรมะรุ้ ไม่น่าใช้\n",
    "\n",
    "#orb initialize\n",
    "orb = cv2.ORB_create()\n",
    "# train_keypoints, train_descriptor = orb.detectAndCompute(training_gray, None)\n",
    "# test_keypoints, test_descriptor = orb.detectAndCompute(test_gray, None)\n",
    "# keypoints_without_size = np.copy(training_image)\n",
    "# keypoints_with_size = np.copy(training_image)\n",
    "# cv2.drawKeypoints(training_image, train_keypoints, keypoints_without_size, color = (0, 255, 0))\n",
    "# cv2.drawKeypoints(training_image, train_keypoints, keypoints_with_size, flags = cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "# # Display image with and without keypoints size\n",
    "# fx, plots = plt.subplots(1, 2, figsize=(20,10))\n",
    "# plots[0].set_title(\"Train keypoints With Size\")\n",
    "# plots[0].imshow(keypoints_with_size, cmap='gray')\n",
    "# plots[1].set_title(\"Train keypoints Without Size\")\n",
    "# plots[1].imshow(keypoints_without_size, cmap='gray')\n",
    "# # Print the number of keypoints detected in the training image\n",
    "# print(\"Number of Keypoints Detected In The Training Image: \", len(train_keypoints))\n",
    "# # Print the number of keypoints detected in the query image\n",
    "# print(\"Number of Keypoints Detected In The Query Image: \", len(test_keypoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "word_dict = {}\n",
    "word_dict[1] = 'sun1'\n",
    "word_dict[2] = 'sun2'\n",
    "word_dict[3] = 'hot1'\n",
    "word_dict[4] = 'hot2'\n",
    "word_dict[5] = 'rain1'\n",
    "word_dict[6] = 'rain2'\n",
    "word_dict[7] = 'snow1'\n",
    "word_dict[8] = 'snow2'\n",
    "word_dict[9] = 'thunder1'\n",
    "word_dict[10] = 'thunder2'\n",
    "word_dict[11] = 'cool1'\n",
    "word_dict[12] = 'cold1'\n",
    "word_dict[13] = 'weather1'\n",
    "word_dict[14] = 'weather2'\n",
    "word_dict[15] = 'warm1'\n",
    "word_dict[16] = 'warm2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hot1 = []\n",
    "hot2 = []\n",
    "cool1 = []\n",
    "cold1 = []\n",
    "rain1 = []\n",
    "rain2 = []\n",
    "snow1 = []\n",
    "snow2 = []\n",
    "thunder1 = []\n",
    "thunder2 = []\n",
    "warm1 = []\n",
    "warm2 = []\n",
    "weather1 = []\n",
    "weather2 = [] \n",
    "sun1 = []\n",
    "sun2 = []\n",
    "\n",
    "\n",
    "###แก้ลูปให้มันรันทุกๆ index\n",
    "for img in img_sun1:\n",
    "     kp, dp = orb.detectAndCompute(img, None)\n",
    "     sun1.append(sun1)\n",
    "     label.append(1)\n",
    "        \n",
    "for img in img_sun2:\n",
    "     kp1, dp1 = orb.detectAndCompute(img, None)\n",
    "     sun2.append(sun2)\n",
    "     label.append(2)\n",
    "for img in img_hot1:\n",
    "     kp2, dp2 = orb.detectAndCompute(img, None)\n",
    "     hot1.append(hot2)\n",
    "     label.append(3)     \n",
    "for img in img_hot2:\n",
    "     kp3, dp3 = orb.detectAndCompute(img, None)\n",
    "     hot2.append(hot2)\n",
    "     label.append(4)\n",
    "for img in img_cool1:\n",
    "     kp4, dp4 = orb.detectAndCompute(img, None)\n",
    "     cool1.append(cool1)\n",
    "     label.append(11)\n",
    "for img in img_cold1:\n",
    "     kp5, dp5 = orb.detectAndCompute(img, None)\n",
    "     cold1.append(cold1)\n",
    "     label.append(12)\n",
    "for img in img_thunder1:\n",
    "     kp6, dp6 = orb.detectAndCompute(img, None)\n",
    "     thunder1.append(thunder1)\n",
    "     label.append(9)\n",
    "for img in img_thunder1:\n",
    "     kp7, dp7 = orb.detectAndCompute(img, None)\n",
    "     thunder2.append(thunder2)\n",
    "     label.append(10)\n",
    "for img in img_weather1:\n",
    "     kp8, dp8 = orb.detectAndCompute(img, None)\n",
    "     weather1.append(weather1)\n",
    "     label.append(13)\n",
    "for img in img_weather2:\n",
    "     kp9, dp9 = orb.detectAndCompute(img, None)\n",
    "     weather2.append(weather2)\n",
    "     label.append(14)\n",
    "for img in img_rain1:\n",
    "     kp10, dp10 = orb.detectAndCompute(img, None)\n",
    "     rain1.append(rain1)\n",
    "     label.append(5)\n",
    "for img in img_rain2:\n",
    "     kp11, dp11 = orb.detectAndCompute(img, None)\n",
    "     rain2.append(rain2)\n",
    "     label.append(6)\n",
    "for img in img_warm1:\n",
    "     kp12, dp12 = orb.detectAndCompute(img, None)\n",
    "     warm1.append(warm1)\n",
    "     label.append(15)\n",
    "for img in img_warm2:\n",
    "     kp13, dp13 = orb.detectAndCompute(img, None)\n",
    "     warm2.append(warm2)\n",
    "     label.append(16)\n",
    "for img in img_snow1:\n",
    "     kp14, dp14 = orb.detectAndCompute(img, None)\n",
    "     snow1.append(snow1)\n",
    "     label.append(7)\n",
    "for img in img_snow2:\n",
    "     kp15, dp15 = orb.detectAndCompute(img, None)\n",
    "     snow2.append(snow2)\n",
    "     label.append(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a Brute Force Matcher object.\n",
    "# bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck = True)\n",
    "\n",
    "# # Perform the matching between the ORB descriptors of the training image and the test image\n",
    "# matches = bf.match(train_descriptor, test_descriptor)\n",
    "\n",
    "# # The matches with shorter distance are the ones we want.\n",
    "# matches = sorted(matches, key = lambda x : x.distance)\n",
    "\n",
    "# result = cv2.drawMatches(training_image, train_keypoints, test_gray, test_keypoints, matches, test_gray, flags = 2)\n",
    "\n",
    "# # Display the best matching points\n",
    "# plt.rcParams['figure.figsize'] = [14.0, 7.0]\n",
    "# plt.title('Best Matching Points')\n",
    "# plt.imshow(result)\n",
    "# plt.show()\n",
    "\n",
    "# # Print total number of matching points between the training and query images\n",
    "# print(\"\\nNumber of Matching Keypoints Between The Training and Query Images: \", len(matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = np.array(dp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,  y_train, y_test  = train_test_split(dp ,label), random_state=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
