{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.2) /Users/travis/build/skvark/opencv-python/opencv/modules/imgproc/src/color.hpp:253: error: (-215:Assertion failed) VScn::contains(scn) && VDcn::contains(dcn) && VDepth::contains(depth) in function 'CvtHelper'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1e739282b646>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Convert the training image to RGB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtraining_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Convert the training image to gray scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(3.4.2) /Users/travis/build/skvark/opencv-python/opencv/modules/imgproc/src/color.hpp:253: error: (-215:Assertion failed) VScn::contains(scn) && VDcn::contains(dcn) && VDepth::contains(depth) in function 'CvtHelper'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the image\n",
    "image1 = cv2.imread('./images/face1.jpeg')\n",
    "\n",
    "# Convert the training image to RGB\n",
    "training_image = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Convert the training image to gray scale\n",
    "training_gray = cv2.cvtColor(training_image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# Create test image by adding Scale Invariance and Rotational Invariance\n",
    "test_image = cv2.pyrDown(training_image)\n",
    "test_image = cv2.pyrDown(test_image)\n",
    "num_rows, num_cols = test_image.shape[:2]\n",
    "\n",
    "rotation_matrix = cv2.getRotationMatrix2D((num_cols/2, num_rows/2), 30, 1)\n",
    "test_image = cv2.warpAffine(test_image, rotation_matrix, (num_cols, num_rows))\n",
    "\n",
    "test_gray = cv2.cvtColor(test_image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# Display traning image and testing image\n",
    "fx, plots = plt.subplots(1, 2, figsize=(20,10))\n",
    "\n",
    "plots[0].set_title(\"Training Image\")\n",
    "plots[0].imshow(training_image)\n",
    "\n",
    "plots[1].set_title(\"Testing Image\")\n",
    "plots[1].imshow(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_gray' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-10dd776763c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0morb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mORB_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_keypoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_descriptor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_gray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtest_keypoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_descriptor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_gray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_gray' is not defined"
     ]
    }
   ],
   "source": [
    "orb = cv2.ORB_create()\n",
    "\n",
    "train_keypoints, train_descriptor = orb.detectAndCompute(training_gray, None)\n",
    "test_keypoints, test_descriptor = orb.detectAndCompute(test_gray, None)\n",
    "\n",
    "keypoints_without_size = np.copy(training_image)\n",
    "keypoints_with_size = np.copy(training_image)\n",
    "\n",
    "cv2.drawKeypoints(training_image, train_keypoints, keypoints_without_size, color = (0, 255, 0))\n",
    "\n",
    "cv2.drawKeypoints(training_image, train_keypoints, keypoints_with_size, flags = cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "# Display image with and without keypoints size\n",
    "fx, plots = plt.subplots(1, 2, figsize=(20,10))\n",
    "\n",
    "plots[0].set_title(\"Train keypoints With Size\")\n",
    "plots[0].imshow(keypoints_with_size, cmap='gray')\n",
    "\n",
    "plots[1].set_title(\"Train keypoints Without Size\")\n",
    "plots[1].imshow(keypoints_without_size, cmap='gray')\n",
    "\n",
    "# Print the number of keypoints detected in the training image\n",
    "print(\"Number of Keypoints Detected In The Training Image: \", len(train_keypoints))\n",
    "\n",
    "# Print the number of keypoints detected in the query image\n",
    "print(\"Number of Keypoints Detected In The Query Image: \", len(test_keypoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_descriptor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d2c93fb8331f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Perform the matching between the ORB descriptors of the training image and the test image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_descriptor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_descriptor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# The matches with shorter distance are the ones we want.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_descriptor' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a Brute Force Matcher object.\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck = True)\n",
    "\n",
    "# Perform the matching between the ORB descriptors of the training image and the test image\n",
    "matches = bf.match(train_descriptor, test_descriptor)\n",
    "\n",
    "# The matches with shorter distance are the ones we want.\n",
    "matches = sorted(matches, key = lambda x : x.distance)\n",
    "\n",
    "result = cv2.drawMatches(training_image, train_keypoints, test_gray, test_keypoints, matches, test_gray, flags = 2)\n",
    "\n",
    "# Display the best matching points\n",
    "plt.rcParams['figure.figsize'] = [14.0, 7.0]\n",
    "plt.title('Best Matching Points')\n",
    "plt.imshow(result)\n",
    "plt.show()\n",
    "\n",
    "# Print total number of matching points between the training and query images\n",
    "print(\"\\nNumber of Matching Keypoints Between The Training and Query Images: \", len(matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
